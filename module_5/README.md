## Техническое задание к модулю 5  

#### 1. Kafka против дубликатов    
В базе данных PostgreSQL хранится таблица user_logins. В ней содержатся события пользователей, такие как логин, регистрация, покупка и т.д. Каждый раз, когда необходимо перенести эти события из PostgreSQL в другую систему (например, ClickHouse), можно воспользоваться Kafka как промежуточным звеном для передачи сообщений. Однако, в реальных задачах возникает риск повторной отправки уже обработанных данных. Чтобы избежать дублирования, нужно использовать дополнительное логическое поле в таблице — sent_to_kafka BOOLEAN, которое будет сигнализировать, были ли данные уже отправлены в Kafka.  

### Инструкция по запуску:  
- указываем параметры подключение к kafka, pg и запускаем [producer.py](https://github.com/to-the-DE/my_internship/blob/main/module_5/producer.py).
  !Важно. Таблица, которая будет отправлять данные в Кафку должна содержать в себе данные, не быть пустой.  
- указываем паарметры подключения к kafka, Clickhouse и запускаем [consumer.py](https://github.com/to-the-DE/my_internship/blob/main/module_5/consumer.py).
